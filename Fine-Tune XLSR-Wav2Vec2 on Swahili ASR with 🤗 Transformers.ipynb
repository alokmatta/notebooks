{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fine-Tune XLSR-Wav2Vec2 on Swahili ASR with ü§ó Transformers.ipynb","provenance":[{"file_id":"1_RL6TQv_Yiu_xbWXu4ycbzdCdXCqEQYU","timestamp":1617013223164},{"file_id":"https://github.com/patrickvonplaten/notebooks/blob/master/Fine_Tune_XLSR_Wav2Vec2_on_Turkish_ASR_with_%F0%9F%A4%97_Transformers.ipynb","timestamp":1616666272588}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6aba2654688544c6bcf3086d7d57b70f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_21231069aa35412fb838b2ee23a4a10e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7a5896aafeda4dcca159b71c3ef22e5c","IPY_MODEL_a302150a182d49fc88c2eadba54b468d"]}},"21231069aa35412fb838b2ee23a4a10e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a5896aafeda4dcca159b71c3ef22e5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_56d9bd85315247938019e8ba6d8dbdfb","_dom_classes":[],"description":"#0: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":4890,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4890,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7152463a01be4165972735b4ea9969c2"}},"a302150a182d49fc88c2eadba54b468d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8fe14230b3c4c339197932def231ef1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4890/4890 [05:09&lt;00:00, 15.78ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5abff9788857476fa7cecb673a3a719f"}},"56d9bd85315247938019e8ba6d8dbdfb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7152463a01be4165972735b4ea9969c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8fe14230b3c4c339197932def231ef1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5abff9788857476fa7cecb673a3a719f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"958e00b161be42cf932fb1149964824b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc5e6c96208c498dbd6fd072c0638f22","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_44034fff8b2d49f5a581c59bcce6adee","IPY_MODEL_5c52ba381fe44bbf8bb8c81593a10e09"]}},"cc5e6c96208c498dbd6fd072c0638f22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44034fff8b2d49f5a581c59bcce6adee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_db34330b98d44362b96380a05876bc1a","_dom_classes":[],"description":"#3:  94%","_model_name":"FloatProgressModel","bar_style":"","max":4889,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4602,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7cf5dada72354a2183588e4579903760"}},"5c52ba381fe44bbf8bb8c81593a10e09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e79d315ccc04a73a0f2dcf63e484bdd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4602/4889 [06:28&lt;00:25, 11.29ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_943f69f8029a490dbe8a685d84b4be72"}},"db34330b98d44362b96380a05876bc1a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7cf5dada72354a2183588e4579903760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e79d315ccc04a73a0f2dcf63e484bdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"943f69f8029a490dbe8a685d84b4be72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"568f44372ba9434a9c889c18e5b741e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_11a14a0ec5e64d7daf3ec2481f28e2b4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b5efb4180d154d20963517ac4c8653b1","IPY_MODEL_7a7d0f08914c4ab6a725390e1967cba6"]}},"11a14a0ec5e64d7daf3ec2481f28e2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5efb4180d154d20963517ac4c8653b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_deb236d0a95344639918a10201a6b955","_dom_classes":[],"description":"#1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":4890,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4890,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_987f2298d38b42c786e7229d4b63ab1e"}},"7a7d0f08914c4ab6a725390e1967cba6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ca2d73194a24ef4854c0e3ffd8ffa9f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4890/4890 [05:09&lt;00:00, 15.79ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6f6137f89b8448e97167cf14bc35373"}},"deb236d0a95344639918a10201a6b955":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"987f2298d38b42c786e7229d4b63ab1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ca2d73194a24ef4854c0e3ffd8ffa9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b6f6137f89b8448e97167cf14bc35373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47a87d35b41741a9abb22011030f7baf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e48ce7511dcf496c8c52ae6c28a967a7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0a163c9d0ad647fb9a24c91d256c29eb","IPY_MODEL_d5e4cccf1044403cbb57cc862f264e1e"]}},"e48ce7511dcf496c8c52ae6c28a967a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a163c9d0ad647fb9a24c91d256c29eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_208560def8a5461d965f3d9630a8c1f3","_dom_classes":[],"description":"#2:  94%","_model_name":"FloatProgressModel","bar_style":"","max":4890,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4614,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f730e99e6944e38b0b8133a79175b55"}},"d5e4cccf1044403cbb57cc862f264e1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_da0a64a517524261b9829e23307472a1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4614/4890 [06:28&lt;00:20, 13.28ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_233aaa667cbf4572b534285df5edc6a5"}},"208560def8a5461d965f3d9630a8c1f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2f730e99e6944e38b0b8133a79175b55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da0a64a517524261b9829e23307472a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"233aaa667cbf4572b534285df5edc6a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"LBSYoWbi-45k"},"source":["# **Fine-tuning XLSR-Wav2Vec2 for Swahili ASR with ü§ó Transformers**"]},{"cell_type":"markdown","metadata":{"id":"f2tgTrPrkQEV"},"source":["#Initiazation\n"]},{"cell_type":"code","metadata":{"id":"yyHthJ9-_zLW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617033437137,"user_tz":-60,"elapsed":1322,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"c839091c-298b-4422-8452-7551b9bd7631"},"source":["%env WANDB_API_KEY=APIKEY  #set w&b api key and HF password\n","%env HF_password=password"],"execution_count":null,"outputs":[{"output_type":"stream","text":["env: WANDB_API_KEY=f0c5aefb5e98a33cdb56a44eec4043a461df9f73\n","env: HF_password=London02!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G4zGAnNVBem3"},"source":["cloud_env = \"colab\"\n","#cloud_env = \"ovh\"\n","if(cloud_env==\"colab\"):\n","  num_cores = 4\n","elif(cloud_env==\"ovh\"):\n","  num_cores = 13"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8eh87Hoee5d"},"source":["%%capture\n","if(cloud_env==\"colab\"):\n","  !pip install git+https://github.com/huggingface/datasets.git\n","  !pip install git+https://github.com/huggingface/transformers.git\n","  !pip install torchaudio\n","  !pip install librosa\n","  !pip install jiwer\n","  !pip install wandb\n","  !pip install ffmpeg-python\n","!pip install gdown  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"boqXMvNmCaUN"},"source":["import os\n","import pandas as pd\n","import re\n","import random\n","import datasets\n","import IPython.display as ipd\n","import numpy as np\n","import yaml\n","import torch\n","import torchaudio\n","import librosa\n","import wandb\n","\n","from datasets import ClassLabel\n","from IPython.display import display, HTML\n","from datasets import load_dataset, load_metric"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQA3SU8Lp-Ni","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617033457689,"user_tz":-60,"elapsed":2610,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"197900c7-bf69-449c-d662-d7ee463df252"},"source":["torch.cuda.is_available()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"jaogS380ABAk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617033464041,"user_tz":-60,"elapsed":2921,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"e2946dad-54b8-4815-87eb-2255c32ccbeb"},"source":["wandb.login()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malokmatta\u001b[0m (use `wandb login --relogin` to force relogin)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Yc49EKjLBOWv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617018067027,"user_tz":-60,"elapsed":49115,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"6226882a-59e7-454e-d51b-3b241356d773"},"source":["if(cloud_env==\"colab\"):\n","  from google.colab import drive  #for Colab\n","  drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"79FZjaI2JByL"},"source":["#if(cloud_env==\"colab\"):\n","#!cd /content/drive/MyDrive/Swahili && zip -r encoded_dataset.zip encoded_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2DGKYEGvtnTi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617033473919,"user_tz":-60,"elapsed":652,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"bb7bc8ac-8c5c-4bbb-fee1-9f91362cb092"},"source":["if(cloud_env==\"colab\"):\n","  gdrive_data_path = \"/content/drive/MyDrive/Swahili\"\n","  checkpoint_dir = gdrive_data_path+\"/chkps2\"\n","  !mkdir {checkpoint_dir}\n","  !mkdir data\n","else:\n","  checkpoint_dir = \"/workspace/output_models/chkps\"\n","  !mkdir /workspace/output_models/chkps"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‚Äò/content/drive/MyDrive/Swahili/chkps2‚Äô: File exists\n","mkdir: cannot create directory ‚Äòdata‚Äô: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lF7kK7AaANCd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617018154170,"user_tz":-60,"elapsed":991,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"c3e23f13-0336-4fd0-a643-d21db92b3ac8"},"source":["!ls -al {checkpoint_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rkLyjhsOtSz5"},"source":["## Note Can Skip to Use pre-processed data if no changes to data"]},{"cell_type":"markdown","metadata":{"id":"iM3G0Eoujjd1"},"source":["# Get all data & copy locally"]},{"cell_type":"code","metadata":{"id":"4ykueQlop-Ng"},"source":["#!gdown https://drive.google.com/uc?id=1OJcvQIaNwqPdKz6OXBpk-eWeurmfc38f\n","#!gdown https://drive.google.com/uc?id=1SNdOKZcE-Y0tjtoovJJeUaCfBP8f4MWU\n","#!gdown https://drive.google.com/uc?id=1Bne4eAbofhAAnX3Ix6uMu5ROszQaUY-r\n","#!mkdir data\n","\n","#!mv data_broadcastnews_sw.tar.bz2 ./data\n","#!mv gamayun-swahili-minikit.tar.gz ./data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BgF6L7HNwX64"},"source":["#!gdown https://drive.google.com/uc?id=1Bne4eAbofhAAnX3Ix6uMu5ROszQaUY-r #over 5gb so potentially problematic\n","\n","#alternate download link if problems with above\n","#!gdown https://drive.google.com/uc?id=1lhifoEY0Kzj6s11W_taKoVW_mAvzzZ04"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cg2SHfBvrklj"},"source":["if(cloud_env==\"colab\"):\n","  !cp {gdrive_data_path}/IWSLT-lowresource.zip ./data\n","elif(cloud_env==\"ovh\"):\n","  !cp ./drive/IWSLT-lowresource.zip ./data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"piWdJivrsTpf"},"source":["if(cloud_env==\"colab\"):\n","  !cp {gdrive_data_path}/gamayun-swahili-minikit.tar.gz ./data\n","elif(cloud_env==\"ovh\"):\n","  !cp ./drive/gamayun-swahili-minikit.tar.gz ./data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDn8AQFpsdEC"},"source":["if(cloud_env==\"colab\"):\n","  !cp {gdrive_data_path}/data_broadcastnews_sw.tar.bz2 ./data\n","elif(cloud_env==\"ovh\"):\n","  !cp ./drive/data_broadcastnews_sw.tar.bz2 ./data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HVOEG0o0rdZ5"},"source":["%%capture\n","!cd ./data && tar -xvf gamayun-swahili-minikit.tar.gz\n","!cd data && bzip2  -d data_broadcastnews_sw.tar.bz2\n","!cd data && tar -xvf data_broadcastnews_sw.tar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K4-8tOgVy19n"},"source":["%%bash  \n","cd data/data_broadcastnews_sw/data/test/wav5   \n","mv SWH-05-20101124/* ./\n","mv SWH-05-20101211/* ./ \n","mv SWH-05-20101222/* ./ \n","mv SWH-15-20110203/* ./ \n","mv SWH-15-20110311/* ./\n","mv SWH-15-20110323/* ./ "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lz7-6SSxw9o6"},"source":["%%capture\n","!mv IWSLT-lowresource.zip ./data\n","!mkdir ./data/IWSLT\n","!unzip ./data/IWSLT-lowresource.zip -d ./data/IWSLT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbTUXAV9o_3N"},"source":["root_dir = !pwd\n","root_dir = root_dir[0]+\"/data\"\n","gamayun_data = os.path.join(root_dir, \"swahili_minikit\")\n","!ls {gamayun_data}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"za0_3-rEvJy7"},"source":["IWSLT_data = os.path.join(root_dir, \"IWSLT/swa-eng\")\n","!ls {IWSLT_data}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ti87QuOp4xaN"},"source":["max_duration =14 #limit length to 14 secs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pfTblxHhp-Nm"},"source":["train_df1 = pd.read_csv(f\"{root_dir}/swahili_minikit.csv\", sep=\"\\t\",names=[\"file\",\"path\",\"duration\",\"text\"], header=None)\n","train_df1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0uDOWuNlp-Nm"},"source":["(train_df1[train_df1.duration>max_duration])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xw8s14trp-N2"},"source":["train_df1 = train_df1[train_df1.duration<=max_duration]\n","train_df1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssr2tSyxlSgy"},"source":["train_df1[\"path\"] = train_df1[\"path\"].apply(lambda path: gamayun_data+\"/\"+path)\n","train_df1 = train_df1[train_df1[\"text\"]!=\"<music>\"]\n","train_df1 = train_df1[train_df1[\"text\"]!=\"<UNK>\"]\n","train_df1[\"text\"] = train_df1[\"text\"].apply(lambda text: re.sub('<music>', '', text))\n","train_df1[\"text\"] = train_df1[\"text\"].apply(lambda text: re.sub('<UNK>', '', text))\n","train_df1[\"text\"] = train_df1[\"text\"].apply(lambda text: text.replace(\"+\",\" Plus\"))\n","train_df1.drop(\"file\", axis=1, inplace=True)\n","train_df1.drop(\"duration\", axis=1, inplace=True)\n","train_df1.reset_index(inplace=True,drop=True)\n","train_df1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IsVsqvI9rHI3"},"source":["i = random.randint(0,len(train_df1))\n","file = train_df1[\"path\"][i]\n","!ls -al {file}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZE22iSMrVEI"},"source":["print(train_df1[\"text\"][i])\n","print()\n","ipd.Audio(file, autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDC_dIaV7Kf7"},"source":["with open(f\"{IWSLT_data}/train/txt/train.yaml\", 'r') as f:\n","    train_df2 = pd.io.json.json_normalize(yaml.load(f))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQFodF41-RuW"},"source":["train_df2[\"text\"] = open(f\"{IWSLT_data}/train/txt/train.swa\").readlines()\n","train_df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Nlx8UUkp-N9"},"source":["train_df2[train_df2.duration>max_duration]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfB-yVxIp-OK"},"source":["train_df2 = train_df2[train_df2.duration<=max_duration]\n","train_df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ok0vSj6_spfE"},"source":["train_df2[\"path\"] = train_df2[\"wav\"].apply(lambda path: IWSLT_data+\"/train/wav/\"+path)\n","train_df2 = train_df2[train_df2[\"text\"]!=\"<music>\"]\n","train_df2 = train_df2[train_df2[\"text\"]!=\"<UNK>\"]\n","train_df2[\"text\"] = train_df2[\"text\"].apply(lambda text: re.sub('<music>', '', text))\n","train_df2[\"text\"] = train_df2[\"text\"].apply(lambda text: re.sub('<UNK>', '', text))\n","train_df2[\"text\"] = train_df2[\"text\"].apply(lambda text: re.sub('\\u200b', '', text))\n","train_df2[\"text\"] = train_df2[\"text\"].apply(lambda text: text.replace(\"\\n\",\"\"))\n","train_df2.drop(\"speaker_id\", axis=1, inplace=True)\n","train_df2.drop(\"wav\", axis=1, inplace=True)\n","train_df2.drop(\"duration\", axis=1, inplace=True)\n","train_df2.drop(\"offset\", axis=1, inplace=True)\n","train_df2.reset_index(inplace=True,drop=True)\n","train_df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sCHcGNMB7K3R"},"source":["i = random.randint(0,len(train_df2))\n","file = train_df2[\"path\"][i]\n","!ls -al {file}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1otttCVvOGD"},"source":["print(train_df2[\"text\"][i])\n","print()\n","ipd.Audio(file, autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9UTcwaKvyUJ"},"source":["with open(f'{IWSLT_data}/valid/txt/valid.yaml', 'r') as f:\n","    test_df2 = pd.io.json.json_normalize(yaml.load(f))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MX9L2rPMv-BW"},"source":["test_df2[\"text\"] = open(f\"{IWSLT_data}/valid/txt/valid.swa\").readlines()\n","test_df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABg6pGEDp-O7"},"source":["test_df2[test_df2.duration>max_duration]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kACEDFPmp-O9"},"source":["test_df2 = test_df2[test_df2.duration<=max_duration]\n","test_df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yc8SnKTSwPT3"},"source":["test_df2[\"path\"] = test_df2[\"wav\"].apply(lambda path: IWSLT_data+\"/valid/wav/\"+path+\".wav\")\n","test_df2 = test_df2[test_df2[\"text\"]!=\"<music>\"]\n","test_df2 = test_df2[test_df2[\"text\"]!=\"<UNK>\"]\n","test_df2[\"text\"] = test_df2[\"text\"].apply(lambda text: re.sub('<music>', '', text))\n","test_df2[\"text\"] = test_df2[\"text\"].apply(lambda text: re.sub('<UNK>', '', text))\n","test_df2[\"text\"] = test_df2[\"text\"].apply(lambda text: text.replace(\"\\n\",\"\"))\n","test_df2[\"text\"] = test_df2[\"text\"].apply(lambda text: text.replace(\"‚Äî \",\"\"))\n","test_df2[\"text\"] = test_df2[\"text\"].apply(lambda text: text.replace(\"(Ê≠¶Ê±â(Êº¢)ËÇ∫ÁÇé/Ê≠¶ËÇ∫)\",\"\"))\n","\n","test_df2.drop(\"speaker_id\", axis=1, inplace=True)\n","test_df2.drop(\"wav\", axis=1, inplace=True)\n","test_df2.drop(\"duration\", axis=1, inplace=True)\n","test_df2.drop(\"offset\", axis=1, inplace=True)\n","test_df2.reset_index(inplace=True, drop=True)\n","test_df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UF0OYdJ3wjRh"},"source":["i = random.randint(0,len(test_df2))\n","file = test_df2[\"path\"][i]\n","!ls -al {file}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zPbEgGBexBao"},"source":["print(test_df2[\"text\"][i])\n","print()\n","ipd.Audio(file, autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qlnTL0zayWvb"},"source":["train_df2 = train_df2.append(train_df1, ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNOjnzad0OCB"},"source":["train_df2.reset_index(inplace=True,drop=True)\n","train_df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMbEO8912psD"},"source":["ALFFA_data = os.path.join(root_dir, \"data_broadcastnews_sw/data\")\n","!ls {ALFFA_data}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcEQU4dd3poW"},"source":["train_df = pd.read_csv(f\"{ALFFA_data}/train/text\", sep=\"\\t\",names=[\"path\",\"text\"], header=None)\n","train_df[\"path\"] = train_df[\"path\"].apply(lambda path: ALFFA_data+\"/train/wav/\"+path.split(\"_\")[0]+\"/\"+path+\".wav\")\n","train_df = train_df[train_df[\"text\"]!=\"<music>\"]\n","train_df = train_df[train_df[\"text\"]!=\"<UNK>\"]\n","train_df[\"text\"] = train_df[\"text\"].apply(lambda text: re.sub('<music>', '', text))\n","train_df[\"text\"] = train_df[\"text\"].apply(lambda text: re.sub('<UNK>', '', text))\n","train_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1DcrFDL3siV"},"source":["i = random.randint(0,len(train_df))\n","file = train_df[\"path\"][i]\n","!ls -al {file}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A6gx60Tj4W4P"},"source":["print(train_df[\"text\"][i])\n","print()\n","ipd.Audio(file, autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"50zQ6yyR4YU6"},"source":["test_df = pd.read_csv(f\"{ALFFA_data}/test/text\", header=None)\n","test_df[\"text\"] = test_df[0].apply(lambda text: text.replace(text.split(\" \")[0]+\" \",\"\"))\n","test_df[\"path\"] = test_df[0].apply(lambda path: path.split(\" \")[0])\n","test_df[\"path\"] = test_df[\"path\"].apply(lambda path: ALFFA_data+\"/test/wav5/\"+path+\".wav\")\n","test_df = test_df.drop(0, axis=1)\n","test_df = test_df[test_df[\"text\"]!=\"<music>\"]\n","test_df = test_df[test_df[\"text\"]!=\"<UNK>\"]\n","test_df[\"text\"] = test_df[\"text\"].apply(lambda text: re.sub('<music>', '', text))\n","test_df[\"text\"] = test_df[\"text\"].apply(lambda text: re.sub('<UNK>', '', text))\n","test_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGcaip0A4bg3"},"source":["i = random.randint(0,len(test_df))\n","file = test_df[\"path\"][i]\n","!ls -al {file}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m1N1DlOH4fpN"},"source":["print(test_df[\"text\"][i])\n","print()\n","ipd.Audio(file, autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQ0j5LBu38ZA"},"source":["train_df = train_df.append(train_df2, ignore_index=True)\n","train_df = train_df.append(test_df2, ignore_index=True) #using IWSLT test data for training instead as this is short\n","#test_df = test_df.append(test_df2, ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aYCnIScfp-PO"},"source":["train_df.reset_index(inplace=True,drop=True)\n","test_df.reset_index(inplace=True,drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wj9VMLyxp-PO"},"source":["train_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLUP0ymi4Pi8"},"source":["print(len(train_df))\n","print(len(test_df))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AC_ghvigp-Pd"},"source":["#torchaudio.set_audio_backend(\"sox_io\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIUALGlRp-Pd"},"source":["duration = []\n","sample_rate = []\n","try:\n","  for i in range(0,len(train_df)):\n","    info = torchaudio.info(train_df.path[i])\n","    duration.append(info.num_frames/info.sample_rate)\n","    sample_rate.append(info.sample_rate)\n","except:\n","    print(\"error at\",train_df[i])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EetpYExzp-Pd"},"source":["from numpy import unique\n","unique(sample_rate,return_counts=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"_Qjd304Wp-Pe"},"source":["duration.sort(reverse=True)\n","duration[0:20]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7aSlL3-wHBuT"},"source":["sum(duration)/3600  #total hours of training data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VA3Kwv8Lp-P2"},"source":["duration = []\n","sample_rate = []\n","try:\n","  for i in range(0,len(test_df)):\n","    info = torchaudio.info(test_df.path[i])\n","    duration.append(info.num_frames/info.sample_rate)\n","    sample_rate.append(info.sample_rate)\n","except:\n","    print(\"error at\",test_df[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBderkesp-P5"},"source":["from numpy import unique\n","unique(sample_rate,return_counts=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"q_escVGMp-P9"},"source":["duration.sort(reverse=True)\n","duration[0:20]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zzHiBkTxIMdI"},"source":["sum(duration)/3600  #total hours of test data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CZ7JBsYZ4nqc"},"source":["#train_df = train_df[0:2000]  #Subset for initital testing\n","#train_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qC8G6Dad4pH5"},"source":["#test_df = test_df[0:500]\n","#test_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlg-eT5e6GGy"},"source":["train_df.to_csv(\"data/train.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n","test_df.to_csv(\"data/test.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n","\n","print(train_df.shape)\n","print(test_df.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EcS_35kkjxxa"},"source":["# Pre-process data"]},{"cell_type":"code","metadata":{"id":"z9up1qDh41c6"},"source":["common_voice_train = datasets.load_dataset(\"csv\", data_files={\"train\": \"data/train.csv\"}, delimiter=\"\\t\")[\"train\"]\n","common_voice_test = datasets.load_dataset(\"csv\", data_files={\"test\": \"data/test.csv\"}, delimiter=\"\\t\")[\"test\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9IaCP3dOTvWk"},"source":["common_voice_train[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"72737oog2F6U"},"source":["def show_random_elements(dataset, num_examples=10):\n","    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","    picks = []\n","    for _ in range(num_examples):\n","        pick = random.randint(0, len(dataset)-1)\n","        while pick in picks:\n","            pick = random.randint(0, len(dataset)-1)\n","        picks.append(pick)\n","    \n","    df = pd.DataFrame(dataset[picks])\n","    display(HTML(df.to_html()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_JUmf3G3b9S"},"source":["show_random_elements(common_voice_train.remove_columns([\"path\"]), num_examples=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svKzVJ_hQGK6"},"source":["import re\n","chars_to_ignore_regex = '[<>\\,\\?\\.\\!\\-\\;\\:\\\"\\‚Äú\\%\\‚Äò\\‚Äù\\ÔøΩ\\!\\+\\$\\&\\(\\)\\u200b\\/\\\\/\\_\\[\\]]'\n","\n","def remove_special_characters(batch):\n","    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower() + \" \"\n","    return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIHocAuTQbBR"},"source":["common_voice_train = common_voice_train.map(remove_special_characters)\n","common_voice_test = common_voice_test.map(remove_special_characters)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBDRAAYxRE6n"},"source":["show_random_elements(common_voice_train.remove_columns([\"path\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LwCshNbbeRZR"},"source":["def extract_all_chars(batch):\n","  all_text = \" \".join(batch[\"text\"])\n","  vocab = list(set(all_text))\n","  return {\"vocab\": [vocab], \"all_text\": [all_text]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_m6uUjjcfbjH"},"source":["vocab_train = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_train.column_names)\n","vocab_test = common_voice_test.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_test.column_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7oVgE8RZSJNP"},"source":["Now, we create the union of all distinct letters in the training dataset and test dataset and convert the resulting list into an enumerated dictionary."]},{"cell_type":"code","metadata":{"id":"aQfneNsmlJI0"},"source":["vocab_list = list(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_0kRndSvqaKk"},"source":["vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n","vocab_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"npbIbBoLgaFX"},"source":["vocab_dict[\"|\"] = vocab_dict[\" \"]\n","del vocab_dict[\" \"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"znF0bNunsjbl"},"source":["vocab_dict[\"[UNK]\"] = len(vocab_dict)\n","vocab_dict[\"[PAD]\"] = len(vocab_dict)\n","len(vocab_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehyUoh9vk191"},"source":["!rm vocab.json\n","import json\n","with open('vocab.json', 'w') as vocab_file:\n","    json.dump(vocab_dict, vocab_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Par9rpypPsml","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617018517538,"user_tz":-60,"elapsed":1229,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"302b9026-670b-4877-b5e0-031defa66617"},"source":["if(cloud_env==\"colab\"):\n","  processor.save_pretrained(gdrive_data_path)\n","  !cp data/test.csv {gdrive_data_path}\n","  !cp data/train.csv {gdrive_data_path}\n","elif:\n","  processor.save_pretrained(\"/workspace/output_models/\")\n","  !cp data/test.csv /workspace/output_models/\n","  !cp data/train.csv /workspace/output_models/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cp: cannot stat 'data/test.csv': No such file or directory\n","cp: cannot stat 'data/train.csv': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DrKnYuvDIoOO"},"source":["Next, we can prepare the dataset."]},{"cell_type":"code","metadata":{"id":"TTCS7W6XJ9BG"},"source":["common_voice_train[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"al9Luo4LPpwJ"},"source":["def speech_file_to_array_fn(batch):\n","    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n","    batch[\"speech\"] = speech_array[0].numpy()\n","    batch[\"sampling_rate\"] = sampling_rate\n","    batch[\"target_text\"] = batch[\"text\"]\n","    batch[\"target_path\"] = batch[\"path\"]\n","    return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afeicUeWlrRL"},"source":["#common_voice_train = common_voice_train.map(speech_file_to_array_fn, remove_columns=common_voice_train.column_names,num_proc=num_cores)\n","#common_voice_test = common_voice_test.map(speech_file_to_array_fn, remove_columns=common_voice_test.column_names,num_proc=num_cores)\n","\n","common_voice_train = common_voice_train.map(speech_file_to_array_fn, remove_columns=common_voice_train.column_names)\n","common_voice_test = common_voice_test.map(speech_file_to_array_fn, remove_columns=common_voice_test.column_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2iyPLHdbzar"},"source":["import librosa\n","import numpy as np\n","\n","def resample(batch):\n","    if batch[\"target_path\"].find(\"data_broadcastnews_sw\") == -1:\n","      batch[\"speech\"] = librosa.resample(np.asarray(batch[\"speech\"]), 48_000, 16_000)\n","    batch[\"sampling_rate\"] = 16_000\n","    return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"M8XB0l98b-3Z"},"source":["common_voice_train = common_voice_train.map(resample,num_proc=4)\n","common_voice_test = common_voice_test.map(resample, num_proc=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dueM6U7Ev0OA"},"source":["rand_int = random.randint(0, len(common_voice_train)-1)\n","\n","ipd.Audio(data=np.asarray(common_voice_train[rand_int][\"speech\"]), autoplay=True, rate=16000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEWdUe_Vjc6P"},"source":["rand_int = random.randint(0, len(common_voice_test)-1)\n","\n","ipd.Audio(data=np.asarray(common_voice_test[rand_int][\"speech\"]), autoplay=True, rate=16000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Po2g7YPuRTx"},"source":["rand_int = random.randint(0, len(common_voice_train)-1)\n","print(rand_int)\n","print(\"Target text:\", common_voice_train[rand_int][\"target_text\"])\n","print(\"Input array shape:\", np.asarray(common_voice_train[rand_int][\"speech\"]).shape)\n","print(\"Sampling rate:\", common_voice_train[rand_int][\"sampling_rate\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJY7I0XAwe9p"},"source":["def prepare_dataset(batch):\n","    # check that all files have the correct sampling rate\n","    assert (\n","        len(set(batch[\"sampling_rate\"])) == 1\n","    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n","\n","    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n","    \n","    with processor.as_target_processor():\n","        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n","    return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-np9xYK-wl8q"},"source":["common_voice_train = common_voice_train.map(prepare_dataset, remove_columns=common_voice_train.column_names, batch_size=8, batched=True,num_proc=num_cores)\n","common_voice_test = common_voice_test.map(prepare_dataset, remove_columns=common_voice_test.column_names, batch_size=8, batched=True, num_proc=num_cores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVi8sqABnqOQ","executionInfo":{"status":"ok","timestamp":1617016671705,"user_tz":-60,"elapsed":968,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"ad140ea5-cba6-47c5-a66b-5db51ce1ffe0"},"source":["common_voice_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_values', 'labels', 'length'],\n","    num_rows: 19559\n","})"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"zJnGkOEuoCJx"},"source":["def input_lengths(example):\n","    example[\"length\"] = len(example[\"input_values\"])\n","    return example"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":230,"referenced_widgets":["6aba2654688544c6bcf3086d7d57b70f","21231069aa35412fb838b2ee23a4a10e","7a5896aafeda4dcca159b71c3ef22e5c","a302150a182d49fc88c2eadba54b468d","56d9bd85315247938019e8ba6d8dbdfb","7152463a01be4165972735b4ea9969c2","f8fe14230b3c4c339197932def231ef1","5abff9788857476fa7cecb673a3a719f","958e00b161be42cf932fb1149964824b","cc5e6c96208c498dbd6fd072c0638f22","44034fff8b2d49f5a581c59bcce6adee","5c52ba381fe44bbf8bb8c81593a10e09","db34330b98d44362b96380a05876bc1a","7cf5dada72354a2183588e4579903760","5e79d315ccc04a73a0f2dcf63e484bdd","943f69f8029a490dbe8a685d84b4be72","568f44372ba9434a9c889c18e5b741e9","11a14a0ec5e64d7daf3ec2481f28e2b4","b5efb4180d154d20963517ac4c8653b1","7a7d0f08914c4ab6a725390e1967cba6","deb236d0a95344639918a10201a6b955","987f2298d38b42c786e7229d4b63ab1e","0ca2d73194a24ef4854c0e3ffd8ffa9f","b6f6137f89b8448e97167cf14bc35373","47a87d35b41741a9abb22011030f7baf","e48ce7511dcf496c8c52ae6c28a967a7","0a163c9d0ad647fb9a24c91d256c29eb","d5e4cccf1044403cbb57cc862f264e1e","208560def8a5461d965f3d9630a8c1f3","2f730e99e6944e38b0b8133a79175b55","da0a64a517524261b9829e23307472a1","233aaa667cbf4572b534285df5edc6a5"]},"id":"9Sx9e8Bmic03","outputId":"62a9f8d7-d85b-4b31-e3dc-71bd4a22f90f"},"source":["common_voice_train = common_voice_train.map(input_lengths, num_proc=num_cores)\n","common_voice_test = common_voice_test.map(input_lengths, num_proc=num_cores)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["    "],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6aba2654688544c6bcf3086d7d57b70f","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='#0', max=4890.0, style=ProgressStyle(description_width='i‚Ä¶"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"958e00b161be42cf932fb1149964824b","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='#3', max=4889.0, style=ProgressStyle(description_width='i‚Ä¶"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"568f44372ba9434a9c889c18e5b741e9","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='#1', max=4890.0, style=ProgressStyle(description_width='i‚Ä¶"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47a87d35b41741a9abb22011030f7baf","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='#2', max=4890.0, style=ProgressStyle(description_width='i‚Ä¶"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8OKRB4wgiq3H"},"source":["if(cloud_env==\"colab\"):\n","  encoded_dataset_dir = gdrive_data_path+\"/encoded_dataset2\"\n","  encoded_dataset_dir_train = encoded_dataset_dir+\"/train\"\n","  encoded_dataset_dir_test = encoded_dataset_dir+\"/test\"\n","else:\n","  encoded_dataset_dir = \"data/encoded_dataset3\"\n","  encoded_dataset_dir_train = encoded_dataset_dir+\"/train\"\n","  encoded_dataset_dir_test = encoded_dataset_dir+\"/test\"\n","\n","!mkdir {encoded_dataset_dir}\n","common_voice_train.save_to_disk(encoded_dataset_dir_train)\n","common_voice_test.save_to_disk(encoded_dataset_dir_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IpdGKx_xi4n5"},"source":["# Use pre-pocessed data\n"]},{"cell_type":"code","metadata":{"id":"i8Bcv20Nhbis"},"source":["if(cloud_env==\"colab\"):\n","  common_voice_train = datasets.load_from_disk(gdrive_data_path+\"/encoded_dataset2/train\")\n","  common_voice_test  = datasets.load_from_disk(gdrive_data_path+\"/encoded_dataset2/test\")\n","elif(cloud_env==\"ovh\"):\n","  common_voice_train = datasets.load_from_disk(\"/workspace/data/encoded_dataset2/train\")\n","  common_voice_test = datasets.load_from_disk(\"/workspace/data/encoded_dataset2/test\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1ZDEwx4wws9","executionInfo":{"status":"ok","timestamp":1617033564874,"user_tz":-60,"elapsed":2716,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"a0216676-09d4-4f0c-a480-e7d78e9fbde4"},"source":["common_voice_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_values', 'labels', 'length'],\n","    num_rows: 19559\n","})"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IU1NmrQxzKMv","executionInfo":{"status":"ok","timestamp":1617018288267,"user_tz":-60,"elapsed":736,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"7edc64bb-1982-4b89-eccf-64fbb1e7993d"},"source":["common_voice_test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_values', 'labels', 'length'],\n","    num_rows: 1991\n","})"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"EqbnUKG--QC6"},"source":["#https://drive.google.com/drive/folders/1vVt1xgxSMHtPTGg07QGqffh6bH-G0rkl?usp=sharing\n","#download encoded features\n","#!gdown https://drive.google.com/uc?id=1vVt1xgxSMHtPTGg07QGqffh6bH-G0rkl "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tborvC9hx88e"},"source":["import logging\n","import os\n","import sys\n","from pathlib import Path\n","from dataclasses import dataclass, field\n","from typing import Any, Dict, List, Optional, Union\n","import collections\n","from multiprocessing import Pool\n","\n","from tqdm.auto import tqdm\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.cuda.amp import autocast\n","import pandas as pd\n","import pyarrow.parquet as pq\n","\n","import datasets\n","import transformers\n","from transformers import (\n","    HfArgumentParser,\n","    Trainer,\n","    TrainingArguments,\n","    Wav2Vec2CTCTokenizer,\n","    Wav2Vec2FeatureExtractor,\n","    Wav2Vec2ForCTC,\n","    Wav2Vec2Processor,\n","    set_seed,\n",")\n","from transformers.trainer_utils import get_last_checkpoint, is_main_process\n","from transformers.trainer_pt_utils import LengthGroupedSampler, DistributedLengthGroupedSampler\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","from dataclasses import dataclass, field\n","from typing import Any, Dict, List, Optional, Union\n","\n","@dataclass\n","class DataCollatorCTCWithPadding:\n","\n","    processor: Wav2Vec2Processor\n","    padding: Union[bool, str] = True\n","    max_length: Optional[int] = None\n","    max_length_labels: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    pad_to_multiple_of_labels: Optional[int] = None\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # split inputs and labels since they have to be of different lenghts and need\n","        # different padding methods\n","        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","\n","        batch = self.processor.pad(\n","            input_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=\"pt\",\n","        )\n","        with self.processor.as_target_processor():\n","            labels_batch = self.processor.pad(\n","                label_features,\n","                padding=self.padding,\n","                max_length=self.max_length_labels,\n","                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n","                return_tensors=\"pt\",\n","            )\n","\n","        # replace padding with -100 to ignore loss correctly\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        batch[\"labels\"] = labels\n","\n","        return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GGIVy-sU3sXI"},"source":["from transformers import Wav2Vec2CTCTokenizer\n","#vocab = \"/content/drive/MyDrive/Swahili/vocab.json\"\n","vocab = \"./vocab.conf\"\n","tokenizer = Wav2Vec2CTCTokenizer(vocab, unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n","\n","from transformers import Wav2Vec2FeatureExtractor\n","\n","feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n","\n","from transformers import Wav2Vec2Processor\n","\n","processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7cqAWIayn6w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617034001126,"user_tz":-60,"elapsed":28810,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"b59cd442-18f9-48ce-cdac-b368447533a1"},"source":["from transformers import Wav2Vec2ForCTC\n","\n","model = Wav2Vec2ForCTC.from_pretrained(\n","    \"facebook/wav2vec2-large-xlsr-53\", \n","    attention_dropout=0.1,\n","    hidden_dropout=0.1,\n","    feat_proj_dropout=0.0,\n","    mask_time_prob=0.05,\n","    layerdrop=0.1,\n","    gradient_checkpointing=True, \n","    ctc_loss_reduction=\"mean\",\n","    ctc_zero_infinity=True,\n","    pad_token_id=processor.tokenizer.pad_token_id,\n","    vocab_size=len(processor.tokenizer)\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BWbsEvpt8ohl"},"source":["#chpk_path = \"/content/drive/MyDrive/Swahili/chkps2/checkpoint-800\"\n","#!cp /content/drive/MyDrive/Swahili/*.json {chpk_path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgLwAchDu2bU","executionInfo":{"status":"ok","timestamp":1617034120675,"user_tz":-60,"elapsed":16352,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"13645f3d-03f1-47ba-cef4-b715fa67a637"},"source":["#from transformers import (Wav2Vec2ForCTC,Wav2Vec2Processor) \n","#processor = Wav2Vec2Processor.from_pretrained(chpk_path)\n","#model = Wav2Vec2ForCTC.from_pretrained(chpk_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lbQf5GuZyQ4_"},"source":["data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Xsux2gmyXso"},"source":["wer_metric = load_metric(\"wer\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XZ-kjweyTy_"},"source":["def compute_metrics(pred):\n","    pred_logits = pred.predictions\n","    pred_ids = np.argmax(pred_logits, axis=-1)\n","\n","    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n","\n","    pred_str = processor.batch_decode(pred_ids)\n","    # we do not want to group tokens when computing the metrics\n","    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n","\n","    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"wer\": wer}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGI8zObtZ3V0"},"source":["model.freeze_feature_extractor()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbeKSV7uzGPP"},"source":["from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","  output_dir=checkpoint_dir,\n","  # output_dir=\"./wav2vec2-large-xlsr-turkish-demo\",\n","  dataloader_num_workers=num_cores,\n","  group_by_length=True,\n","  per_device_train_batch_size=16,\n","  per_device_eval_batch_size=16,\n","  gradient_accumulation_steps=2,\n","  evaluation_strategy=\"steps\",\n","  num_train_epochs=30,\n","  fp16=True,\n","  save_steps=400,\n","  eval_steps=400,\n","  logging_steps=400,\n","  learning_rate=3e-4,\n","  warmup_steps=500,\n","  save_total_limit=2,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oB7IdYBXiBgx"},"source":["from torch import nn\n","class GroupedLengthsTrainer(Trainer):\n","    # length_field_name should possibly be part of TrainingArguments instead\n","    def __init__(self, length_field_name=None, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.length_field_name = length_field_name\n","    \n","    def _get_train_sampler(self):\n","        if isinstance(self.train_dataset, torch.utils.data.IterableDataset) or not isinstance(\n","            self.train_dataset, collections.abc.Sized\n","        ):\n","            return None\n","\n","        # Build the sampler.\n","        if self.args.group_by_length:\n","            lengths = self.train_dataset[self.length_field_name] if self.length_field_name is not None else None\n","            model_input_name = self.tokenizer.model_input_names[0] if self.tokenizer is not None else None\n","            if self.args.world_size <= 1:\n","                return LengthGroupedSampler(\n","                    self.train_dataset, self.args.train_batch_size, lengths=lengths, model_input_name=model_input_name\n","                )\n","            else:\n","                return DistributedLengthGroupedSampler(\n","                    self.train_dataset,\n","                    self.args.train_batch_size,\n","                    num_replicas=self.args.world_size,\n","                    rank=self.args.process_index,\n","                    lengths=lengths,\n","                    model_input_name=model_input_name,\n","                )\n","\n","        else:\n","            return super()._get_train_sampler()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1yIyGdaIp-SY"},"source":["#!ls /workspace/output_models/chkps"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OsW-WZcL1ZtN"},"source":["Now, all instances can be passed to Trainer and we are ready to start training!"]},{"cell_type":"code","metadata":{"id":"rY7vBmFCPFgC"},"source":["\n","trainer = GroupedLengthsTrainer(\n","    model=model,\n","    length_field_name=\"length\",\n","    data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset=common_voice_train,\n","    eval_dataset=common_voice_test,\n","    tokenizer=processor.feature_extractor,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsvsZMMhp-Sc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617034194290,"user_tz":-60,"elapsed":800,"user":{"displayName":"Alok Matta","photoUrl":"","userId":"16716392443807219300"}},"outputId":"eef9a777-1cc0-4a7d-af23-2bce0bfef3d3"},"source":["trainer.args"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TrainingArguments(output_dir=/content/drive/MyDrive/Swahili/chkps2, overwrite_output_dir=False, do_train=False, do_eval=None, do_predict=False, evaluation_strategy=IntervalStrategy.STEPS, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, gradient_accumulation_steps=2, eval_accumulation_steps=None, learning_rate=0.0003, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=30, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=500, logging_dir=runs/Mar29_16-09-03_6e2e8443c85e, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=400, save_strategy=IntervalStrategy.STEPS, save_steps=400, save_total_limit=2, no_cuda=False, seed=42, fp16=True, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=400, dataloader_num_workers=4, past_index=-1, run_name=/content/drive/MyDrive/Swahili/chkps2, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=True, report_to=['tensorboard', 'wandb'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=1)"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"rpvZHM1xReIW"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"Xh8jhr810H93"},"source":["torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yn6Wwl-Ap-Se"},"source":["import transformers\n","transformers.logging.set_verbosity(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UEjJqGsQw24","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"06fb7862-fbcb-42ee-9719-7a0f34d6476e"},"source":["trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["***** Running training *****\n","  Num examples = 19559\n","  Num Epochs = 30\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 18330\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.23<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">/content/drive/MyDrive/Swahili/chkps2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/alokmatta/huggingface\" target=\"_blank\">https://wandb.ai/alokmatta/huggingface</a><br/>\n","                Run page: <a href=\"https://wandb.ai/alokmatta/huggingface/runs/1eabyphf\" target=\"_blank\">https://wandb.ai/alokmatta/huggingface/runs/1eabyphf</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20210329_161003-1eabyphf</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:760: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1133' max='18330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 1133/18330 1:02:19 < 15:47:37, 0.30 it/s, Epoch 1.85/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Wer</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>400</td>\n","      <td>0.199800</td>\n","      <td>0.343685</td>\n","      <td>0.397062</td>\n","      <td>81.495300</td>\n","      <td>24.431000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.196200</td>\n","      <td>0.370291</td>\n","      <td>0.417740</td>\n","      <td>80.371100</td>\n","      <td>24.773000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 1991\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Swahili/chkps2/checkpoint-400\n","Configuration saved in /content/drive/MyDrive/Swahili/chkps2/checkpoint-400/config.json\n","Model weights saved in /content/drive/MyDrive/Swahili/chkps2/checkpoint-400/pytorch_model.bin\n","Configuration saved in /content/drive/MyDrive/Swahili/chkps2/checkpoint-400/preprocessor_config.json\n","Deleting older checkpoint [/content/drive/MyDrive/Swahili/chkps2/checkpoint-3200] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1991\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Swahili/chkps2/checkpoint-800\n","Configuration saved in /content/drive/MyDrive/Swahili/chkps2/checkpoint-800/config.json\n","Model weights saved in /content/drive/MyDrive/Swahili/chkps2/checkpoint-800/pytorch_model.bin\n","Configuration saved in /content/drive/MyDrive/Swahili/chkps2/checkpoint-800/preprocessor_config.json\n","Deleting older checkpoint [/content/drive/MyDrive/Swahili/chkps2/checkpoint-3600] due to args.save_total_limit\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1601' max='18330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 1601/18330 1:28:41 < 15:27:50, 0.30 it/s, Epoch 2.62/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Wer</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>400</td>\n","      <td>0.199800</td>\n","      <td>0.343685</td>\n","      <td>0.397062</td>\n","      <td>81.495300</td>\n","      <td>24.431000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.196200</td>\n","      <td>0.370291</td>\n","      <td>0.417740</td>\n","      <td>80.371100</td>\n","      <td>24.773000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.181200</td>\n","      <td>0.355469</td>\n","      <td>0.400226</td>\n","      <td>80.327300</td>\n","      <td>24.786000</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='104' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [104/125 01:01 < 00:12, 1.66 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 1991\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Swahili/chkps2/checkpoint-1200\n","Configuration saved in /content/drive/MyDrive/Swahili/chkps2/checkpoint-1200/config.json\n","Model weights saved in /content/drive/MyDrive/Swahili/chkps2/checkpoint-1200/pytorch_model.bin\n","Configuration saved in /content/drive/MyDrive/Swahili/chkps2/checkpoint-1200/preprocessor_config.json\n","Deleting older checkpoint [/content/drive/MyDrive/Swahili/chkps2/checkpoint-400] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1991\n","  Batch size = 16\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"nFlU4NkA6Ftu"},"source":["#Generate script-mode training (For DDP)"]},{"cell_type":"code","metadata":{"id":"5CxN1G825u6a","cellView":"form"},"source":["#@title train.py generator\n","%%writefile train.py\n","\n","#!/usr/bin/env python3\n","import json\n","import logging\n","import os\n","import re\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Any, Dict, List, Optional, Union\n","\n","import datasets\n","import numpy as np\n","import torch\n","import torchaudio\n","from packaging import version\n","from torch import nn\n","import wandb\n","\n","import transformers\n","from transformers import (\n","    HfArgumentParser,\n","    Trainer,\n","    TrainingArguments,\n","    Wav2Vec2CTCTokenizer,\n","    Wav2Vec2FeatureExtractor,\n","    Wav2Vec2ForCTC,\n","    Wav2Vec2Processor,\n","    is_apex_available,\n","    set_seed,\n",")\n","from transformers.trainer_utils import get_last_checkpoint, is_main_process\n","\n","\n","if is_apex_available():\n","    from apex import amp\n","\n","\n","if version.parse(torch.__version__) >= version.parse(\"1.6\"):\n","    _is_native_amp_available = True\n","    from torch.cuda.amp import autocast\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","def list_field(default=None, metadata=None):\n","    return field(default_factory=lambda: default, metadata=metadata)\n","\n","\n","@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n","    )\n","    freeze_feature_extractor: Optional[bool] = field(\n","        default=True, metadata={\"help\": \"Whether to freeze the feature extractor layers of the model.\"}\n","    )\n","    attention_dropout: Optional[float] = field(\n","        default=0.1, metadata={\"help\": \"The dropout ratio for the attention probabilities.\"}\n","    )\n","    activation_dropout: Optional[float] = field(\n","        default=0.1, metadata={\"help\": \"The dropout ratio for activations inside the fully connected layer.\"}\n","    )\n","    hidden_dropout: Optional[float] = field(\n","        default=0.1,\n","        metadata={\n","            \"help\": \"The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.\"\n","        },\n","    )\n","    feat_proj_dropout: Optional[float] = field(\n","        default=0.1,\n","        metadata={\"help\": \"The dropout probabilitiy for all 1D convolutional layers in feature extractor.\"},\n","    )\n","    mask_time_prob: Optional[float] = field(\n","        default=0.05,\n","        metadata={\n","            \"help\": \"Propability of each feature vector along the time axis to be chosen as the start of the vector\"\n","            \"span to be masked. Approximately ``mask_time_prob * sequence_length // mask_time_length`` feature\"\n","            \"vectors will be masked along the time axis. This is only relevant if ``apply_spec_augment is True``.\"\n","        },\n","    )\n","    gradient_checkpointing: Optional[bool] = field(\n","        default=True,\n","        metadata={\n","            \"help\": \"If True, use gradient checkpointing to save memory at the expense of slower backward pass.\"\n","        },\n","    )\n","    layerdrop: Optional[float] = field(default=0.0, metadata={\"help\": \"The LayerDrop probability.\"})\n","\n","\n","@dataclass\n","class DataTrainingArguments:\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","    Using `HfArgumentParser` we can turn this class\n","    into argparse arguments to be able to specify them on\n","    the command line.\n","    \"\"\"\n","\n","    dataset_config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n","    )\n","    train_split_name: Optional[str] = field(\n","        default=\"train+validation\",\n","        metadata={\n","            \"help\": \"The name of the training data set split to use (via the datasets library). Defaults to 'train'\"\n","        },\n","    )\n","    overwrite_cache: bool = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n","    )\n","    preprocessing_num_workers: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n","    )\n","    max_train_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_val_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of validation examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    chars_to_ignore: List[str] = list_field(\n","        default=[\",\", \"?\", \".\", \"!\", \"-\", \";\", \":\", '\"\"', \"%\", \"'\", '\"', \"ÔøΩ\"],\n","        metadata={\"help\": \"A list of characters to remove from the transcripts.\"},\n","    )\n","\n","\n","@dataclass\n","class DataCollatorCTCWithPadding:\n","    \"\"\"\n","    Data collator that will dynamically pad the inputs received.\n","    Args:\n","        processor (:class:`~transformers.Wav2Vec2Processor`)\n","            The processor used for proccessing the data.\n","        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n","            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n","            among:\n","            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n","              sequence if provided).\n","            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n","              maximum acceptable input length for the model if that argument is not provided.\n","            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n","              different lengths).\n","        max_length (:obj:`int`, `optional`):\n","            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n","        max_length_labels (:obj:`int`, `optional`):\n","            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n","        pad_to_multiple_of (:obj:`int`, `optional`):\n","            If set will pad the sequence to a multiple of the provided value.\n","            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n","            7.5 (Volta).\n","    \"\"\"\n","\n","    processor: Wav2Vec2Processor\n","    padding: Union[bool, str] = True\n","    max_length: Optional[int] = None\n","    max_length_labels: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    pad_to_multiple_of_labels: Optional[int] = None\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # split inputs and labels since they have to be of different lenghts and need\n","        # different padding methods\n","        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","\n","        batch = self.processor.pad(\n","            input_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=\"pt\",\n","        )\n","        with self.processor.as_target_processor():\n","            labels_batch = self.processor.pad(\n","                label_features,\n","                padding=self.padding,\n","                max_length=self.max_length_labels,\n","                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n","                return_tensors=\"pt\",\n","            )\n","\n","        # replace padding with -100 to ignore loss correctly\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        batch[\"labels\"] = labels\n","\n","        return batch\n","\n","\n","class CTCTrainer(Trainer):\n","    def training_step(self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n","        \"\"\"\n","        Perform a training step on a batch of inputs.\n","        Subclass and override to inject custom behavior.\n","        Args:\n","            model (:obj:`nn.Module`):\n","                The model to train.\n","            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n","                The inputs and targets of the model.\n","                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n","                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n","        Return:\n","            :obj:`torch.Tensor`: The tensor with training loss on this batch.\n","        \"\"\"\n","\n","        model.train()\n","        inputs = self._prepare_inputs(inputs)\n","\n","        if self.use_amp:\n","            with autocast():\n","                loss = self.compute_loss(model, inputs)\n","        else:\n","            loss = self.compute_loss(model, inputs)\n","\n","        if self.args.n_gpu > 1:\n","            if model.module.config.ctc_loss_reduction == \"mean\":\n","                loss = loss.mean()\n","            elif model.module.config.ctc_loss_reduction == \"sum\":\n","                loss = loss.sum() / (inputs[\"labels\"] >= 0).sum()\n","            else:\n","                raise ValueError(f\"{model.config.ctc_loss_reduction} is not valid. Choose one of ['mean', 'sum']\")\n","\n","        if self.args.gradient_accumulation_steps > 1:\n","            loss = loss / self.args.gradient_accumulation_steps\n","\n","        if self.use_amp:\n","            self.scaler.scale(loss).backward()\n","        elif self.use_apex:\n","            with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n","                scaled_loss.backward()\n","        elif self.deepspeed:\n","            self.deepspeed.backward(loss)\n","        else:\n","            loss.backward()\n","\n","        return loss.detach()\n","\n","\n","def main():\n","    # See all possible arguments in src/transformers/training_args.py\n","    # or by passing the --help flag to this script.\n","    # We now keep distinct sets of args, for a cleaner separation of concerns.\n","\n","    wandb.login()\n","    \n","    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n","    if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n","        # If we pass only one argument to the script and it's the path to a json file,\n","        # let's parse it to get our arguments.\n","        model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n","    else:\n","        model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n","\n","    # Detecting last checkpoint.\n","    last_checkpoint = None\n","    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n","        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n","        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n","            raise ValueError(\n","                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n","                \"Use --overwrite_output_dir to overcome.\"\n","            )\n","        elif last_checkpoint is not None:\n","            logger.info(\n","                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n","                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n","            )\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        handlers=[logging.StreamHandler(sys.stdout)],\n","    )\n","    logger.setLevel(logging.INFO if is_main_process(training_args.local_rank) else logging.WARN)\n","\n","    # Log on each process the small summary:\n","    logger.warning(\n","        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n","        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n","    )\n","    # Set the verbosity to info of the Transformers logger (on main process only):\n","    if is_main_process(training_args.local_rank):\n","        transformers.utils.logging.set_verbosity_info()\n","    logger.info(\"Training/evaluation parameters %s\", training_args)\n","\n","    # Set seed before initializing model.\n","    set_seed(training_args.seed)\n","\n","    # Get the datasets:\n","    \n","    train_dataset = load_from_disk(\"/content/drive/MyDrive/Swahili/encoded_dataset/train\")  \n","\n","    eval_dataset = load_from_disk(\"/content/drive/MyDrive/Swahili/encoded_dataset/test\")  \n","\n","    # Load pretrained model and tokenizer\n","    #\n","    # Distributed training:\n","    # The .from_pretrained methods guarantee that only one local process can concurrently\n","    # download model & vocab.\n","    tokenizer = Wav2Vec2CTCTokenizer(\n","        \"vocab.json\",\n","        unk_token=\"[UNK]\",\n","        pad_token=\"[PAD]\",\n","        word_delimiter_token=\"|\",\n","    )\n","    feature_extractor = Wav2Vec2FeatureExtractor(\n","        feature_size=1, sampling_rate=16_000, padding_value=0.0, do_normalize=True, return_attention_mask=True\n","    )\n","    processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n","    model = Wav2Vec2ForCTC.from_pretrained(\n","        model_args.model_name_or_path,\n","        cache_dir=model_args.cache_dir,\n","        activation_dropout=model_args.activation_dropout,\n","        attention_dropout=model_args.attention_dropout,\n","        hidden_dropout=model_args.hidden_dropout,\n","        feat_proj_dropout=model_args.feat_proj_dropout,\n","        mask_time_prob=model_args.mask_time_prob,\n","        gradient_checkpointing=model_args.gradient_checkpointing,\n","        layerdrop=model_args.layerdrop,\n","        ctc_loss_reduction=\"mean\",\n","        pad_token_id=processor.tokenizer.pad_token_id,\n","        vocab_size=len(processor.tokenizer),\n","    )\n","\n","    if data_args.max_train_samples is not None:\n","        train_dataset = train_dataset.select(range(data_args.max_train_samples))\n","\n","    if data_args.max_val_samples is not None:\n","        eval_dataset = eval_dataset.select(range(data_args.max_val_samples))\n","\n","    resampler = torchaudio.transforms.Resample(48_000, 16_000)\n","\n","    # Preprocessing the datasets.\n","    # We need to read the aduio files as arrays and tokenize the targets.\n","    def speech_file_to_array_fn(batch):\n","        speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n","        batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n","        batch[\"sampling_rate\"] = 16_000\n","        batch[\"target_text\"] = batch[\"text\"]\n","        return batch\n","\n","    train_dataset = train_dataset.map(\n","        speech_file_to_array_fn,\n","        remove_columns=train_dataset.column_names,\n","        num_proc=data_args.preprocessing_num_workers,\n","    )\n","    eval_dataset = eval_dataset.map(\n","        speech_file_to_array_fn,\n","        remove_columns=eval_dataset.column_names,\n","        num_proc=data_args.preprocessing_num_workers,\n","    )\n","\n","    def prepare_dataset(batch):\n","        # check that all files have the correct sampling rate\n","        assert (\n","            len(set(batch[\"sampling_rate\"])) == 1\n","        ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n","        batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n","        # Setup the processor for targets\n","        with processor.as_target_processor():\n","            batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n","        return batch\n","\n","    train_dataset = train_dataset.map(\n","        prepare_dataset,\n","        remove_columns=train_dataset.column_names,\n","        batch_size=training_args.per_device_train_batch_size,\n","        batched=True,\n","        num_proc=data_args.preprocessing_num_workers,\n","    )\n","    eval_dataset = eval_dataset.map(\n","        prepare_dataset,\n","        remove_columns=eval_dataset.column_names,\n","        batch_size=training_args.per_device_train_batch_size,\n","        batched=True,\n","        num_proc=data_args.preprocessing_num_workers,\n","    )\n","\n","    # Metric\n","    wer_metric = datasets.load_metric(\"wer\")\n","\n","    def compute_metrics(pred):\n","        pred_logits = pred.predictions\n","        pred_ids = np.argmax(pred_logits, axis=-1)\n","\n","        pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n","\n","        pred_str = processor.batch_decode(pred_ids)\n","        # we do not want to group tokens when computing the metrics\n","        label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n","\n","        wer = wer_metric.compute(predictions=pred_str, references=label_str)\n","\n","        return {\"wer\": wer}\n","\n","    if model_args.freeze_feature_extractor:\n","        model.freeze_feature_extractor()\n","\n","    # Data collator\n","    data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n","\n","    # Initialize our Trainer\n","    trainer = CTCTrainer(\n","        model=model,\n","        data_collator=data_collator,\n","        args=training_args,\n","        compute_metrics=compute_metrics,\n","        train_dataset=train_dataset if training_args.do_train else None,\n","        eval_dataset=eval_dataset if training_args.do_eval else None,\n","        tokenizer=processor.feature_extractor,\n","    )\n","\n","    # Training\n","    if training_args.do_train:\n","        if last_checkpoint is not None:\n","            checkpoint = last_checkpoint\n","        elif os.path.isdir(model_args.model_name_or_path):\n","            checkpoint = model_args.model_name_or_path\n","        else:\n","            checkpoint = None\n","        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","        trainer.save_model()\n","\n","        # save the feature_extractor and the tokenizer\n","        if is_main_process(training_args.local_rank):\n","            processor.save_pretrained(training_args.output_dir)\n","\n","        metrics = train_result.metrics\n","        max_train_samples = (\n","            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n","        )\n","        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","        trainer.log_metrics(\"train\", metrics)\n","        trainer.save_metrics(\"train\", metrics)\n","        trainer.save_state()\n","\n","    # Evaluation\n","    results = {}\n","    if training_args.do_eval:\n","        logger.info(\"*** Evaluate ***\")\n","        metrics = trainer.evaluate()\n","        max_val_samples = data_args.max_val_samples if data_args.max_val_samples is not None else len(eval_dataset)\n","        metrics[\"eval_samples\"] = min(max_val_samples, len(eval_dataset))\n","\n","        trainer.log_metrics(\"eval\", metrics)\n","        trainer.save_metrics(\"eval\", metrics)\n","\n","    return results\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AEO329G45u6f","cellView":"form"},"source":["#@title train.sh generator to run in terminal\n","%%writefile train.sh\n","# run from Command line\n","# !python train.py\n","# python -m torch.distributed.launch \\\n","#\t--nproc_per_node 4 run_common_voice.py \\\n","%%bash\n","python train.py \\\n","\t--model_name_or_path=\"facebook/wav2vec2-large-xlsr-53\" \\\n","\t--dataset_config_name=\"tr\" \\\n","\t--output_dir=./drive/MyDrive/Swahili/testchkps \\\n","\t--overwrite_output_dir \\\n","\t--num_train_epochs=\"5\" \\\n","\t--per_device_train_batch_size=\"16\" \\\n","\t--learning_rate=\"3e-4\" \\\n","\t--warmup_steps=\"500\" \\\n","\t--evaluation_strategy=\"steps\" \\\n","\t--save_steps=\"400\" \\\n","\t--eval_steps=\"400\" \\\n","\t--logging_steps=\"400\" \\\n","\t--save_total_limit=\"3\" \\\n","\t--freeze_feature_extractor \\\n","\t--feat_proj_dropout=\"0.0\" \\\n","\t--layerdrop=\"0.1\" \\\n","\t--gradient_checkpointing \\\n","\t--fp16 \\\n","\t--group_by_length \\\n","\t--do_train --do_eval"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MlwRlzgFDu7m"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Ok3TRznhB-kj"},"source":["#Publish Model\n"]},{"cell_type":"code","metadata":{"id":"oxZJmU_1stCf"},"source":["%%bash\n","git clone https://alokmatta:password@huggingface.co/alokmatta/wav2vec2-large-xlsr-53-sw\n","sudo apt-get install git-lfs\n","cd wav2vec2-large-xlsr-53-sw\n","git lfs install\n","git config --global user.email ‚Äúalokmatta‚Äù@gmail.com\n","git config --global user.name ‚ÄúAlok‚Äù"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jfN3UGatP2-"},"source":["checkpoint_to_upload=2400"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y6KG0HS07xbN"},"source":["!cp /content/drive/MyDrive/Swahili/checkpoints/checkpoint-{checkpoint_to_upload}/* ./wav2vec2-large-xlsr-53-sw/\n","!cp /content/drive/MyDrive/Swahili/preprocessor_config.json ./wav2vec2-large-xlsr-53-sw/\n","!cp /content/drive/MyDrive/Swahili/special_tokens_map.json ./wav2vec2-large-xlsr-53-sw/\n","!cp /content/drive/MyDrive/Swahili/tokenizer_config.json ./wav2vec2-large-xlsr-53-sw/\n","!cp /content/drive/MyDrive/Swahili/vocab.json ./wav2vec2-large-xlsr-53-sw/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGE0JCl2tInv"},"source":["%%bash\n","cd wav2vec2-large-xlsr-53-sw\n","git add .\n","git commit -m ‚Äúbaseline-0.12‚Äù\n","git push"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9imH9ZqYCMhF"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"J8E8pxJ9hgZS"},"source":["from transformers import (Wav2Vec2ForCTC,Wav2Vec2Processor)\n","#model = Wav2Vec2ForCTC.from_pretrained(\"alokmatta/wav2vec2-large-xlsr-53-sw\").to(\"cuda\")\n","model = Wav2Vec2ForCTC.from_pretrained(\"alokmatta/wav2vec2-large-xlsr-53-sw\")\n","processor = Wav2Vec2Processor.from_pretrained(\"alokmatta/wav2vec2-large-xlsr-53-sw\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_D4FkXwCkPT"},"source":["#@title Run audio script { display-mode: \"form\" }\n","## script created by Eric Lam\n","AUDIO_HTML = \"\"\"\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"fqa__OjDCr0w"},"source":["#@title Process Audio\n","## code created by Eric Lam\n","from IPython.display import HTML, Audio\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import wave\n","from scipy.io.wavfile import read as wav_read\n","import io\n","import numpy as np\n","import ffmpeg\n","import torchaudio\n","import torch\n","import re\n","import sys\n","\n","def write_wav(f, sr, x, normalized=False):\n","    f = wave.open(f, \"wb\")\n","    f.setnchannels(1)\n","    f.setsampwidth(2)\n","    f.setframerate(sr)\n","    \n","    wave_data = x.astype(np.short)\n","    f.writeframes(wave_data.tobytes())\n","    f.close()\n","\n","def get_audio():\n","  global hnum\n","\n","  # call microphone\n","  display(HTML(AUDIO_HTML))\n","  data = eval_js(\"data\")\n","  binary = b64decode(data.split(',')[1])\n","\n","  process = (ffmpeg\n","      .input('pipe:0')\n","      .output('pipe:1', format='wav')\n","      .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n","  )\n","  output, err = process.communicate(input=binary)\n","\n","  riff_chunk_size = len(output) - 8\n","  # Break up the chunk size into four bytes, held in b.\n","  q = riff_chunk_size\n","  b = []\n","  for i in range(4):\n","      q, r = divmod(q, 256)\n","      b.append(r)\n","\n","  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n","  riff = output[:4] + bytes(b) + output[8:]\n","  sr, audio = wav_read(io.BytesIO(riff))\n","  # save\n","  human_sound_file = \"demo.wav\"\n","  write_wav(human_sound_file, sr, audio)\n","\n","  return human_sound_file\n","\n","resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)\n","\n","def load_file_to_data(file):\n","    batch = {}\n","    speech, _ = torchaudio.load(file)\n","    batch[\"speech\"] = resampler.forward(speech.squeeze(0)).numpy()\n","    batch[\"sampling_rate\"] = resampler.new_freq\n","    return batch\n","\n","\n","def predict(data):\n","    features = processor(data[\"speech\"], sampling_rate=data[\"sampling_rate\"], padding=True, return_tensors=\"pt\")\n","    #input_values = features.input_values.to(\"cuda\")\n","    #attention_mask = features.attention_mask.to(\"cuda\")\n","    input_values = features.input_values\n","    attention_mask = features.attention_mask\n","    with torch.no_grad():\n","        logits = model(input_values, attention_mask=attention_mask).logits\n","    pred_ids = torch.argmax(logits, dim=-1)\n","    return processor.batch_decode(pred_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Boe3i7aHC6te"},"source":["get_audio()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wX62KH6WC-pr"},"source":["predict(load_file_to_data('./demo.wav'))"],"execution_count":null,"outputs":[]}]}